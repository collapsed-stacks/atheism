## If we use "complexity and capacity for suffering as a guide for moral hierarchy," what happens when we encounter beings more complex than us?

- posted by: [James Kelly](https://stackexchange.com/users/-1/1271-james-kelly) on 2011-03-14
- tagged: `morality`
- score: 6

Sam Harris, for example, argues in [*The Moral Landscape*](http://en.wikipedia.org/wiki/The_Moral_Landscape), and I generally agree, that the measure of moral culpability for a death is tied to the complexity and capacity for suffering of the thing dying. This is why it's ok for complex humans to eat less complex fish. Or why killing a baby is much more egregious than terminating a pregnancy.

The sticking point for me with this definition is this, what happens if we encounter aliens who are more complex than us? From another angle, if we create an intelligence that is smarter than we are? Wouldn't that mean that we would have to put our own life's worth below that of these more complex entities? Especially if their capacity for suffering can be measured as greater than our own. Wouldn't then we be compelled to put their lives ahead of ours?


## Answer 3160

- posted by: [Rex Kerr](https://stackexchange.com/users/-1/1166-rex-kerr) on 2011-03-15
- score: 3

Sam Harris, for example, argues in [*The Moral Landscape*](http://en.wikipedia.org/wiki/The_Moral_Landscape), and I generally agree, that the measure of moral culpability for a death is tied to the complexity and capacity for suffering of the thing dying. This is why it's ok for complex humans to eat less complex fish. Or why killing a baby is much more egregious than terminating a pregnancy.

The sticking point for me with this definition is this, what happens if we encounter aliens who are more complex than us? From another angle, if we create an intelligence that is smarter than we are? Wouldn't that mean that we would have to put our own life's worth below that of these more complex entities? Especially if their capacity for suffering can be measured as greater than our own. Wouldn't then we be compelled to put their lives ahead of ours?


## Answer 3154

- posted by: [Jimbo](https://stackexchange.com/users/-1/1258-jimbo) on 2011-03-15
- score: 2

Sam Harris, for example, argues in [*The Moral Landscape*](http://en.wikipedia.org/wiki/The_Moral_Landscape), and I generally agree, that the measure of moral culpability for a death is tied to the complexity and capacity for suffering of the thing dying. This is why it's ok for complex humans to eat less complex fish. Or why killing a baby is much more egregious than terminating a pregnancy.

The sticking point for me with this definition is this, what happens if we encounter aliens who are more complex than us? From another angle, if we create an intelligence that is smarter than we are? Wouldn't that mean that we would have to put our own life's worth below that of these more complex entities? Especially if their capacity for suffering can be measured as greater than our own. Wouldn't then we be compelled to put their lives ahead of ours?


## Answer 3150

- posted by: [jaskey13](https://stackexchange.com/users/-1/1107-jaskey13) on 2011-03-14
- score: 1

Sam Harris, for example, argues in [*The Moral Landscape*](http://en.wikipedia.org/wiki/The_Moral_Landscape), and I generally agree, that the measure of moral culpability for a death is tied to the complexity and capacity for suffering of the thing dying. This is why it's ok for complex humans to eat less complex fish. Or why killing a baby is much more egregious than terminating a pregnancy.

The sticking point for me with this definition is this, what happens if we encounter aliens who are more complex than us? From another angle, if we create an intelligence that is smarter than we are? Wouldn't that mean that we would have to put our own life's worth below that of these more complex entities? Especially if their capacity for suffering can be measured as greater than our own. Wouldn't then we be compelled to put their lives ahead of ours?


## Answer 3176

- posted by: [Konrad Rudolph](https://stackexchange.com/users/-1/82-konrad-rudolph) on 2011-03-16
- score: 1

Sam Harris, for example, argues in [*The Moral Landscape*](http://en.wikipedia.org/wiki/The_Moral_Landscape), and I generally agree, that the measure of moral culpability for a death is tied to the complexity and capacity for suffering of the thing dying. This is why it's ok for complex humans to eat less complex fish. Or why killing a baby is much more egregious than terminating a pregnancy.

The sticking point for me with this definition is this, what happens if we encounter aliens who are more complex than us? From another angle, if we create an intelligence that is smarter than we are? Wouldn't that mean that we would have to put our own life's worth below that of these more complex entities? Especially if their capacity for suffering can be measured as greater than our own. Wouldn't then we be compelled to put their lives ahead of ours?


## Answer 3153

- posted by: [Dogmafrog](https://stackexchange.com/users/-1/1266-dogmafrog) on 2011-03-15
- score: 0

Sam Harris, for example, argues in [*The Moral Landscape*](http://en.wikipedia.org/wiki/The_Moral_Landscape), and I generally agree, that the measure of moral culpability for a death is tied to the complexity and capacity for suffering of the thing dying. This is why it's ok for complex humans to eat less complex fish. Or why killing a baby is much more egregious than terminating a pregnancy.

The sticking point for me with this definition is this, what happens if we encounter aliens who are more complex than us? From another angle, if we create an intelligence that is smarter than we are? Wouldn't that mean that we would have to put our own life's worth below that of these more complex entities? Especially if their capacity for suffering can be measured as greater than our own. Wouldn't then we be compelled to put their lives ahead of ours?


## Answer 3156

- posted by: [Lauren Ipsum](https://stackexchange.com/users/-1/71-lauren-ipsum) on 2011-03-15
- score: 0

Sam Harris, for example, argues in [*The Moral Landscape*](http://en.wikipedia.org/wiki/The_Moral_Landscape), and I generally agree, that the measure of moral culpability for a death is tied to the complexity and capacity for suffering of the thing dying. This is why it's ok for complex humans to eat less complex fish. Or why killing a baby is much more egregious than terminating a pregnancy.

The sticking point for me with this definition is this, what happens if we encounter aliens who are more complex than us? From another angle, if we create an intelligence that is smarter than we are? Wouldn't that mean that we would have to put our own life's worth below that of these more complex entities? Especially if their capacity for suffering can be measured as greater than our own. Wouldn't then we be compelled to put their lives ahead of ours?


## Answer 3162

- posted by: [Lausten](https://stackexchange.com/users/-1/584-lausten) on 2011-03-15
- score: 0

Sam Harris, for example, argues in [*The Moral Landscape*](http://en.wikipedia.org/wiki/The_Moral_Landscape), and I generally agree, that the measure of moral culpability for a death is tied to the complexity and capacity for suffering of the thing dying. This is why it's ok for complex humans to eat less complex fish. Or why killing a baby is much more egregious than terminating a pregnancy.

The sticking point for me with this definition is this, what happens if we encounter aliens who are more complex than us? From another angle, if we create an intelligence that is smarter than we are? Wouldn't that mean that we would have to put our own life's worth below that of these more complex entities? Especially if their capacity for suffering can be measured as greater than our own. Wouldn't then we be compelled to put their lives ahead of ours?



---

All content is licensed under the [CC BY-SA 3.0 license](https://creativecommons.org/licenses/by-sa/3.0/).
